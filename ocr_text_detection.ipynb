{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ocr_text_detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgAtvLfkhAQr",
        "outputId": "6f8b23b1-ca51-4414-96fa-bf10c2b253ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building OCR Model"
      ],
      "metadata": {
        "id": "QfqTTME23BY6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "e4boF1m_1cyE"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "def load_mnist_dataset():\n",
        "\n",
        "  # load data from tensorflow framework\n",
        "  ((trainData, trainLabels), (testData, testLabels)) = mnist.load_data() \n",
        "\n",
        "  # Stacking train data and test data to form single array named data\n",
        "  data = np.vstack([trainData, testData]) \n",
        "\n",
        "  # Vertical stacking labels of train and test set\n",
        "  labels = np.hstack([trainLabels, testLabels]) \n",
        "\n",
        "  # return a 2-tuple of the MNIST data and labels\n",
        "  return (data, labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_az_dataset(datasetPath):\n",
        "\n",
        "  # List for storing data\n",
        "  data = []\n",
        "  \n",
        "  # List for storing labels\n",
        "  labels = []\n",
        "  \n",
        "  for row in open(datasetPath): #Openfile and start reading each row\n",
        "    #Split the row at every comma\n",
        "    row = row.split(\",\")\n",
        "    \n",
        "    #row[0] contains label\n",
        "    label = int(row[0])\n",
        "    \n",
        "    #Other all collumns contains pixel values make a saperate array for that\n",
        "    image = np.array([int(x) for x in row[1:]], dtype=\"uint8\")\n",
        "    \n",
        "    #Reshaping image to 28 x 28 pixels\n",
        "    image = image.reshape((28, 28))\n",
        "    \n",
        "    #append image to data\n",
        "    data.append(image)\n",
        "    \n",
        "    #append label to labels\n",
        "    labels.append(label)\n",
        "    \n",
        "  #Converting data to numpy array of type float32\n",
        "  data = np.array(data, dtype='float32')\n",
        "  \n",
        "  #Converting labels to type int\n",
        "  labels = np.array(labels, dtype=\"int\")\n",
        "  \n",
        "  return (data, labels)"
      ],
      "metadata": {
        "id": "Jl0xN8h_17OF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(digitsData, digitsLabels) = load_mnist_dataset()\n",
        "\n",
        "(azData, azLabels) = load_az_dataset('/content/drive/MyDrive/Colab Notebooks/ocr/A_Z Handwritten Data.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66gutPuQ2C0G",
        "outputId": "acbf05d7-a706-4354-b268-60254cae6cb8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combining datasets and dataset preparation"
      ],
      "metadata": {
        "id": "qkqTHgAR3Khv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "# the MNIST dataset occupies the labels 0-9, so let's add 10 to every A-Z label to ensure the A-Z characters are not incorrectly labeled \n",
        "\n",
        "azLabels += 10\n",
        "\n",
        "# stack the A-Z data and labels with the MNIST digits data and labels\n",
        "\n",
        "data = np.vstack([azData, digitsData])\n",
        "labels = np.hstack([azLabels, digitsLabels])\n",
        "\n",
        "# Each image in the A-Z and MNIST digts datasets are 28x28 pixels;\n",
        "# However, the architecture we're using is designed for 32x32 images,\n",
        "# So we need to resize them to 32x32\n",
        "\n",
        "data = [cv2.resize(image, (32, 32)) for image in data]\n",
        "data = np.array(data, dtype=\"float32\")\n",
        "\n",
        "# add a channel dimension to every image in the dataset and scale the\n",
        "# pixel intensities of the images from [0, 255] down to [0, 1]\n",
        "\n",
        "data = np.expand_dims(data, axis=-1)\n",
        "data /= 255.0"
      ],
      "metadata": {
        "id": "Fq3B7bwm2zZZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "le = LabelBinarizer()\n",
        "labels = le.fit_transform(labels)\n",
        "\n",
        "counts = labels.sum(axis=0)\n",
        "\n",
        "# account for skew in the labeled data\n",
        "classTotals = labels.sum(axis=0)\n",
        "classWeight = {}\n",
        "\n",
        "# loop over all classes and calculate the class weight\n",
        "for i in range(0, len(classTotals)):\n",
        "  classWeight[i] = classTotals.max() / classTotals[i]"
      ],
      "metadata": {
        "id": "tk-3ZuVb24C1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing Data Augmentation"
      ],
      "metadata": {
        "id": "7zFtyS033q3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# construct the image generator for data augmentation\n",
        "\n",
        "aug = ImageDataGenerator(\n",
        "rotation_range=10,\n",
        "zoom_range=0.05,\n",
        "width_shift_range=0.1,\n",
        "height_shift_range=0.1,\n",
        "shear_range=0.15,\n",
        "horizontal_flip=False,\n",
        "fill_mode=\"nearest\")"
      ],
      "metadata": {
        "id": "EAfPWcAI3iwC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building ResNet Architecture"
      ],
      "metadata": {
        "id": "u62MrrCO31Bt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import (\n",
        "    BatchNormalization, SeparableConv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\n",
        ")\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import add\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "class ResNet:\n",
        "\t@staticmethod\n",
        "\tdef residual_module(data, K, stride, chanDim, red=False,\n",
        "\t\treg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
        "\t\t# the shortcut branch of the ResNet module should be\n",
        "\t\t# initialize as the input (identity) data\n",
        "\t\tshortcut = data\n",
        "\n",
        "\t\t# the first block of the ResNet module are the 1x1 CONVs\n",
        "\t\tbn1 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
        "\t\t\tmomentum=bnMom)(data)\n",
        "\t\tact1 = Activation(\"relu\")(bn1)\n",
        "\t\tconv1 = Conv2D(int(K * 0.25), (1, 1), use_bias=False,\n",
        "\t\t\tkernel_regularizer=l2(reg))(act1)\n",
        "\n",
        "\t\t# the second block of the ResNet module are the 3x3 CONVs\n",
        "\t\tbn2 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
        "\t\t\tmomentum=bnMom)(conv1)\n",
        "\t\tact2 = Activation(\"relu\")(bn2)\n",
        "\t\tconv2 = Conv2D(int(K * 0.25), (3, 3), strides=stride,\n",
        "\t\t\tpadding=\"same\", use_bias=False,\n",
        "\t\t\tkernel_regularizer=l2(reg))(act2)\n",
        "\n",
        "\t\t# the third block of the ResNet module is another set of 1x1\n",
        "\t\t# CONVs\n",
        "\t\tbn3 = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
        "\t\t\tmomentum=bnMom)(conv2)\n",
        "\t\tact3 = Activation(\"relu\")(bn3)\n",
        "\t\tconv3 = Conv2D(K, (1, 1), use_bias=False,\n",
        "\t\t\tkernel_regularizer=l2(reg))(act3)\n",
        "\n",
        "\t\t# if we are to reduce the spatial size, apply a CONV layer to\n",
        "\t\t# the shortcut\n",
        "\t\tif red:\n",
        "\t\t\tshortcut = Conv2D(K, (1, 1), strides=stride,\n",
        "\t\t\t\tuse_bias=False, kernel_regularizer=l2(reg))(act1)\n",
        "\n",
        "\t\t# add together the shortcut and the final CONV\n",
        "\t\tx = add([conv3, shortcut])\n",
        "\n",
        "\t\t# return the addition as the output of the ResNet module\n",
        "\t\treturn x\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef build(width, height, depth, classes, stages, filters,\n",
        "\t\treg=0.0001, bnEps=2e-5, bnMom=0.9, dataset=\"cifar\"):\n",
        "\t\t# initialize the input shape to be \"channels last\" and the\n",
        "\t\t# channels dimension itself\n",
        "\t\tinputShape = (height, width, depth)\n",
        "\t\tchanDim = -1\n",
        "\n",
        "\t\t# if we are using \"channels first\", update the input shape\n",
        "\t\t# and channels dimension\n",
        "\t\tif K.image_data_format() == \"channels_first\":\n",
        "\t\t\tinputShape = (depth, height, width)\n",
        "\t\t\tchanDim = 1\n",
        "\n",
        "\t\t# set the input and apply BN\n",
        "\t\tinputs = Input(shape=inputShape)\n",
        "\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
        "\t\t\tmomentum=bnMom)(inputs)\n",
        "\n",
        "\t\t# check if we are utilizing the CIFAR dataset\n",
        "\t\tif dataset == \"cifar\":\n",
        "\t\t\t# apply a single CONV layer\n",
        "\t\t\tx = Conv2D(filters[0], (3, 3), use_bias=False,\n",
        "\t\t\t\tpadding=\"same\", kernel_regularizer=l2(reg))(x)\n",
        "\n",
        "\t\t# check to see if we are using the Tiny ImageNet dataset\n",
        "\t\telif dataset == \"tiny_imagenet\":\n",
        "\t\t\t# apply CONV => BN => ACT => POOL to reduce spatial size\n",
        "\t\t\tx = Conv2D(filters[0], (5, 5), use_bias=False,\n",
        "\t\t\t\tpadding=\"same\", kernel_regularizer=l2(reg))(x)\n",
        "\t\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
        "\t\t\t\tmomentum=bnMom)(x)\n",
        "\t\t\tx = Activation(\"relu\")(x)\n",
        "\t\t\tx = ZeroPadding2D((1, 1))(x)\n",
        "\t\t\tx = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "\t\t# loop over the number of stages\n",
        "\t\tfor i in range(0, len(stages)):\n",
        "\t\t\t# initialize the stride, then apply a residual module\n",
        "\t\t\t# used to reduce the spatial size of the input volume\n",
        "\t\t\tstride = (1, 1) if i == 0 else (2, 2)\n",
        "\t\t\tx = ResNet.residual_module(x, filters[i + 1], stride,\n",
        "\t\t\t\tchanDim, red=True, bnEps=bnEps, bnMom=bnMom)\n",
        "\n",
        "\t\t\t# loop over the number of layers in the stage\n",
        "\t\t\tfor j in range(0, stages[i] - 1):\n",
        "\t\t\t\t# apply a ResNet module\n",
        "\t\t\t\tx = ResNet.residual_module(x, filters[i + 1],\n",
        "\t\t\t\t\t(1, 1), chanDim, bnEps=bnEps, bnMom=bnMom)\n",
        "\n",
        "\t\t# apply BN => ACT => POOL\n",
        "\t\tx = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
        "\t\t\tmomentum=bnMom)(x)\n",
        "\t\tx = Activation(\"relu\")(x)\n",
        "\t\tx = AveragePooling2D((8, 8))(x)\n",
        "\n",
        "\t\t# softmax classifier\n",
        "\t\tx = Flatten()(x)\n",
        "\t\tx = Dense(classes, kernel_regularizer=l2(reg))(x)\n",
        "\t\tx = Activation(\"softmax\")(x)\n",
        "\n",
        "\t\t# create the model\n",
        "\t\tmodel = Model(inputs, x, name=\"resnet\")\n",
        "\n",
        "\t\t# return the constructed network architecture\n",
        "\t\treturn model"
      ],
      "metadata": {
        "id": "TFoffmHW3zR3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling model"
      ],
      "metadata": {
        "id": "xGlEkoCj4Bzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "\n",
        "EPOCHS = 50\n",
        "INIT_LR = 1e-1\n",
        "BS = 128\n",
        "\n",
        "opt = SGD(learning_rate=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "\n",
        "model = ResNet.build(32, 32, 1, len(le.classes_), (3, 3, 3),\n",
        "(64, 64, 128, 256), reg=0.0005)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
        "\n",
        "H = model.fit(\n",
        "aug.flow(trainX, trainY, batch_size=BS),\n",
        "validation_data=(testX, testY),\n",
        "steps_per_epoch=len(trainX) // BS,epochs=EPOCHS,\n",
        "class_weight=classWeight,\n",
        "verbose=1)"
      ],
      "metadata": {
        "id": "GEFMngU739LV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "3bc59782-f309-4252-8cf8-726a74c50457"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-7d02fc383a62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m H = model.fit(\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0maug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trainX' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation"
      ],
      "metadata": {
        "id": "rJISrcR74asL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labelNames = \"0123456789\"\n",
        "\n",
        "labelNames += \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "\n",
        "labelNames = [l for l in labelNames]\n",
        "\n",
        "predictions = model.predict(testX, batch_size=BS)\n",
        "\n",
        "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=labelNames))"
      ],
      "metadata": {
        "id": "t6snLdxz4Mw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Model"
      ],
      "metadata": {
        "id": "CbK2imPl4fWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('OCR_Resnet.h5',save_format=\".h5\")"
      ],
      "metadata": {
        "id": "_85sFpEH4Uhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Testing"
      ],
      "metadata": {
        "id": "XWWcZ6bY4lwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "# randomly select a few testing characters\n",
        "\n",
        "for i in np.random.choice(np.arange(0, len(testY)), size=(49,)):\n",
        "  probs = model.predict(testX[np.newaxis, i])\n",
        "  prediction = probs.argmax(axis=1)\n",
        "  label = labelNames[prediction[0]]\n",
        "  output+=label\n",
        "  image = (testX[i] * 255).astype(\"uint8\")\n",
        "  color = (0, 255, 0)\n",
        "  if prediction[0] != np.argmax(testY[i]):\n",
        "  color = (0, 0, 255)\n",
        "  image = cv2.merge([image] * 3)\n",
        "  image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
        "  cv2.putText(image, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75,\n",
        "  color, 2)\n",
        "  images.append(image)\n",
        "  \n",
        "montage = build_montages(images, (96, 96), (7, 7))[0]\n",
        "cv2_imshow(montage)\n",
        "cv2.waitKey(0)"
      ],
      "metadata": {
        "id": "2fB9FLPN4nVU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}